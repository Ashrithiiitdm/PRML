{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Consider the 128- dimensional feature vectors given in the “face feature vectors.csv” file.\n",
    "\n",
    "Dataset Specifications:\n",
    "\n",
    "Total number of samples = 800\n",
    "\n",
    "Number of classes = 2 ( labeled as “male” and “female”)\n",
    "\n",
    "Samples from “1 to 400” belongs to class “male”\n",
    "\n",
    "Samples from “401 to 800” belongs to class “female”\n",
    "\n",
    "Number of samples per class = 400\n",
    "\n",
    "Use the following information to design classifier:\n",
    "\n",
    "Number of test samples ( last 5 in each class) = 5\n",
    "\n",
    "Number of training samples ( remaining 395 in each class) = 395\n",
    "\n",
    "Number of dimensions = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.066420</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>-0.066105</td>\n",
       "      <td>-0.041232</td>\n",
       "      <td>-0.002637</td>\n",
       "      <td>-0.158467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>-0.046754</td>\n",
       "      <td>-0.118619</td>\n",
       "      <td>-0.163774</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>-0.076400</td>\n",
       "      <td>0.107497</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.030614</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>-0.050324</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>-0.063818</td>\n",
       "      <td>-0.019530</td>\n",
       "      <td>-0.119905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>-0.028108</td>\n",
       "      <td>0.040618</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>-0.141244</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.080610</td>\n",
       "      <td>-0.015930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.096178</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>-0.035388</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>-0.018634</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>-0.139786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111141</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>-0.029222</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>-0.222173</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>0.093428</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.057652</td>\n",
       "      <td>0.086116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.103057</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>-0.035873</td>\n",
       "      <td>-0.028163</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>-0.017016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100793</td>\n",
       "      <td>-0.002644</td>\n",
       "      <td>-0.023388</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>-0.015100</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.062462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.125815</td>\n",
       "      <td>0.120046</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>-0.042901</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>-0.049677</td>\n",
       "      <td>-0.054258</td>\n",
       "      <td>-0.130758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090197</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>0.039926</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>-0.056852</td>\n",
       "      <td>-0.076700</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.026041</td>\n",
       "      <td>0.084135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.149119</td>\n",
       "      <td>0.125288</td>\n",
       "      <td>0.142323</td>\n",
       "      <td>-0.009087</td>\n",
       "      <td>-0.031394</td>\n",
       "      <td>-0.123533</td>\n",
       "      <td>0.043598</td>\n",
       "      <td>-0.063999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060833</td>\n",
       "      <td>0.089529</td>\n",
       "      <td>-0.034872</td>\n",
       "      <td>0.057080</td>\n",
       "      <td>-0.137162</td>\n",
       "      <td>-0.072522</td>\n",
       "      <td>0.052731</td>\n",
       "      <td>-0.141460</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.085765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.139035</td>\n",
       "      <td>0.073513</td>\n",
       "      <td>-0.001770</td>\n",
       "      <td>-0.034225</td>\n",
       "      <td>-0.101610</td>\n",
       "      <td>0.065105</td>\n",
       "      <td>-0.014420</td>\n",
       "      <td>-0.054993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081007</td>\n",
       "      <td>-0.002164</td>\n",
       "      <td>0.060377</td>\n",
       "      <td>0.080294</td>\n",
       "      <td>-0.139369</td>\n",
       "      <td>-0.150245</td>\n",
       "      <td>0.078657</td>\n",
       "      <td>0.024194</td>\n",
       "      <td>0.062180</td>\n",
       "      <td>0.036039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.074126</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>-0.082413</td>\n",
       "      <td>-0.096091</td>\n",
       "      <td>-0.021992</td>\n",
       "      <td>0.009714</td>\n",
       "      <td>-0.056961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050497</td>\n",
       "      <td>0.038932</td>\n",
       "      <td>0.023520</td>\n",
       "      <td>-0.090260</td>\n",
       "      <td>-0.147692</td>\n",
       "      <td>-0.008296</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>-0.026687</td>\n",
       "      <td>-0.017523</td>\n",
       "      <td>-0.038310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.166220</td>\n",
       "      <td>0.042769</td>\n",
       "      <td>-0.031647</td>\n",
       "      <td>-0.036892</td>\n",
       "      <td>-0.143837</td>\n",
       "      <td>-0.040566</td>\n",
       "      <td>0.042541</td>\n",
       "      <td>-0.122923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014732</td>\n",
       "      <td>-0.049135</td>\n",
       "      <td>0.081770</td>\n",
       "      <td>-0.027199</td>\n",
       "      <td>-0.096941</td>\n",
       "      <td>-0.094661</td>\n",
       "      <td>0.057797</td>\n",
       "      <td>-0.101063</td>\n",
       "      <td>0.061373</td>\n",
       "      <td>0.062176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>male</td>\n",
       "      <td>-0.185770</td>\n",
       "      <td>0.154008</td>\n",
       "      <td>0.073184</td>\n",
       "      <td>-0.070829</td>\n",
       "      <td>-0.144617</td>\n",
       "      <td>-0.019732</td>\n",
       "      <td>-0.019418</td>\n",
       "      <td>-0.004675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093317</td>\n",
       "      <td>0.035101</td>\n",
       "      <td>-0.147997</td>\n",
       "      <td>-0.046010</td>\n",
       "      <td>-0.087777</td>\n",
       "      <td>-0.100660</td>\n",
       "      <td>0.036190</td>\n",
       "      <td>0.012158</td>\n",
       "      <td>0.032304</td>\n",
       "      <td>0.085996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Unnamed: 1         0         1         2         3         4  \\\n",
       "0           1       male -0.066420  0.151611  0.027740  0.052771 -0.066105   \n",
       "1           2       male -0.030614  0.049667  0.008084 -0.050324  0.007649   \n",
       "2           3       male -0.096178  0.061127  0.035326 -0.035388 -0.090728   \n",
       "3           4       male -0.103057  0.085044  0.078333 -0.035873 -0.028163   \n",
       "4           5       male -0.125815  0.120046  0.023131 -0.042901  0.038215   \n",
       "5           6       male -0.149119  0.125288  0.142323 -0.009087 -0.031394   \n",
       "6           7       male -0.139035  0.073513 -0.001770 -0.034225 -0.101610   \n",
       "7           8       male -0.074126 -0.000669  0.004166 -0.082413 -0.096091   \n",
       "8           9       male -0.166220  0.042769 -0.031647 -0.036892 -0.143837   \n",
       "9          10       male -0.185770  0.154008  0.073184 -0.070829 -0.144617   \n",
       "\n",
       "          5         6         7  ...       118       119       120       121  \\\n",
       "0 -0.041232 -0.002637 -0.158467  ...  0.025989 -0.001087  0.027260 -0.046754   \n",
       "1 -0.063818 -0.019530 -0.119905  ...  0.044229 -0.023900 -0.028108  0.040618   \n",
       "2 -0.018634 -0.024315 -0.139786  ...  0.111141  0.059436 -0.029222  0.042115   \n",
       "3  0.004924  0.007829 -0.017016  ...  0.100793 -0.002644 -0.023388  0.029497   \n",
       "4 -0.049677 -0.054258 -0.130758  ...  0.090197  0.067527  0.039926  0.047469   \n",
       "5 -0.123533  0.043598 -0.063999  ...  0.060833  0.089529 -0.034872  0.057080   \n",
       "6  0.065105 -0.014420 -0.054993  ...  0.081007 -0.002164  0.060377  0.080294   \n",
       "7 -0.021992  0.009714 -0.056961  ...  0.050497  0.038932  0.023520 -0.090260   \n",
       "8 -0.040566  0.042541 -0.122923  ...  0.014732 -0.049135  0.081770 -0.027199   \n",
       "9 -0.019732 -0.019418 -0.004675  ...  0.093317  0.035101 -0.147997 -0.046010   \n",
       "\n",
       "        122       123       124       125       126       127  \n",
       "0 -0.118619 -0.163774 -0.000590 -0.076400  0.107497  0.001567  \n",
       "1 -0.146579 -0.141244  0.016162  0.017638  0.080610 -0.015930  \n",
       "2 -0.222173 -0.116908  0.093428  0.017391  0.057652  0.086116  \n",
       "3 -0.139830 -0.119243  0.005306 -0.015100  0.161575  0.062462  \n",
       "4 -0.056852 -0.076700  0.004966  0.028171  0.026041  0.084135  \n",
       "5 -0.137162 -0.072522  0.052731 -0.141460  0.019018  0.085765  \n",
       "6 -0.139369 -0.150245  0.078657  0.024194  0.062180  0.036039  \n",
       "7 -0.147692 -0.008296  0.007609 -0.026687 -0.017523 -0.038310  \n",
       "8 -0.096941 -0.094661  0.057797 -0.101063  0.061373  0.062176  \n",
       "9 -0.087777 -0.100660  0.036190  0.012158  0.032304  0.085996  \n",
       "\n",
       "[10 rows x 130 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_df = pd.read_csv('./face_feature_vectors.csv')\n",
    "face_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Function to check whether the data falls under case 1\n",
    "def isCase1(mat):\n",
    "    first = mat[0][0]\n",
    "    for i in range(1, len(mat)):\n",
    "        if mat[i][i] != first:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "#If the data falls under case-1 discriminant function is computed accordingly.\n",
    "def linear_case1(w, pw, cov_mat):\n",
    "    u1 = np.mean(w, axis=0)\n",
    "    cov = cov_mat[0][0]\n",
    "    weight = u1 / cov\n",
    "    bias = np.log(pw) - 0.5 * np.dot(u1.T, u1) / (cov ** 2)\n",
    "    return weight, bias\n",
    "\n",
    "#If the data falls under case-2 discriminant function is computed accordingly.\n",
    "def linear_case2(w, pw, cov_mat):\n",
    "    u1 = np.mean(w, axis=0)\n",
    "    inv_cov = np.linalg.inv(cov_mat)\n",
    "    weight = inv_cov @ u1\n",
    "    bias = np.log(pw) - 0.5 * u1.T @ inv_cov @ u1\n",
    "    return weight, bias\n",
    "\n",
    "#If the data falls under case-3 discriminant function is computed accordingly.\n",
    "def non_linear(w, pw, cov_mat):\n",
    "    u1 = np.mean(w, axis=0)\n",
    "    inv_cov = np.linalg.inv(cov_mat)\n",
    "    weight1 = -0.5 * inv_cov\n",
    "    weight2 = inv_cov @ u1\n",
    "    bias = np.log(pw) - 0.5 * np.log(np.linalg.det(cov_mat)) - 0.5 * u1.T @ inv_cov @ u1\n",
    "    return weight1, weight2, bias\n",
    "\n",
    "\n",
    "#wieghts and biases are extracted from above functions by checking the cases for the given data.\n",
    "def bayes_classifier(w1, w2, pw1, pw2):\n",
    "    w1_cov = np.cov(w1, rowvar=False)\n",
    "    w2_cov = np.cov(w2, rowvar=False)\n",
    "    \n",
    "    if np.allclose(w1_cov, w2_cov):\n",
    "        weight1, bias1 = linear_case2(w1, pw1, w1_cov)\n",
    "        weight2, bias2 = linear_case2(w2, pw2, w2_cov)\n",
    "        return lambda x: np.dot(weight1 - weight2, x) + (bias1 - bias2)\n",
    "    elif isCase1(w1_cov) and isCase1(w2_cov):\n",
    "        weight1, bias1 = linear_case1(w1, pw1, w1_cov)\n",
    "        weight2, bias2 = linear_case1(w2, pw2, w2_cov)\n",
    "        return lambda x: np.dot(weight1 - weight2, x) + (bias1 - bias2)\n",
    "    else:\n",
    "        weight1_1, weight1_2, bias1 = non_linear(w1, pw1, w1_cov)\n",
    "        weight2_1, weight2_2, bias2 = non_linear(w2, pw2, w2_cov)\n",
    "        return lambda x: x.T @ (weight1_1 - weight2_1) @ x + np.dot(weight1_2 - weight2_2, x) + (bias1 - bias2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 classes\n",
    "n = 2\n",
    "\n",
    "#No of features\n",
    "features = 128\n",
    "\n",
    "#as first 400 are male and next 400 are female\n",
    "labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "#Testing dataset\n",
    "test_male_df = face_df.iloc[395 : 400]\n",
    "test_female_df = face_df.iloc[795 : 800]\n",
    "\n",
    "test_male_df = test_male_df.drop(columns = ['Unnamed: 1', 'Unnamed: 0'])\n",
    "test_female_df = test_female_df.drop(columns = ['Unnamed: 1', 'Unnamed: 0'])\n",
    "\n",
    "test_male_labels = labels[395 : 400] \n",
    "test_female_labels = labels[795 : 800]\n",
    "\n",
    "#Training dataset\n",
    "training_male_df = face_df.iloc[: 395]\n",
    "training_female_df = face_df.iloc[400 : 795]\n",
    "\n",
    "training_male_df = training_male_df.drop(columns = ['Unnamed: 1', 'Unnamed: 0'])\n",
    "training_female_df = training_female_df.drop(columns = ['Unnamed: 1', 'Unnamed: 0'])\n",
    "\n",
    "\n",
    "train_male_labels = labels[: 395]\n",
    "test_female_labels = labels[400 : 795]\n",
    "\n",
    "pw1, pw2 = 0.5, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 50.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4991/2425728545.py:32: RuntimeWarning: divide by zero encountered in log\n",
      "  bias = np.log(pw) - 0.5 * np.log(np.linalg.det(cov_mat)) - 0.5 * u1.T @ inv_cov @ u1\n",
      "/tmp/ipykernel_4991/2425728545.py:52: RuntimeWarning: invalid value encountered in scalar subtract\n",
      "  return lambda x: x.T @ (weight1_1 - weight2_1) @ x + np.dot(weight1_2 - weight2_2, x) + (bias1 - bias2)\n"
     ]
    }
   ],
   "source": [
    "result = bayes_classifier(training_male_df, training_female_df, pw1, pw2)\n",
    "test_df = np.vstack((test_male_df, test_female_df))\n",
    "test_labels = np.array([0] * 5 + [1] * 5)\n",
    "predictions = np.array([0 if result(x) > 0 else 1 for x in test_df])\n",
    "\n",
    "accuracy = np.mean(test_labels == predictions)*100\n",
    "print(\"Accuracy of the model is\", accuracy, \"%\")\n",
    "\n",
    "#pred = np.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: True label = Male, Predicted = Female\n",
      "Sample 2: True label = Male, Predicted = Female\n",
      "Sample 3: True label = Male, Predicted = Female\n",
      "Sample 4: True label = Male, Predicted = Female\n",
      "Sample 5: True label = Male, Predicted = Female\n",
      "Sample 6: True label = Female, Predicted = Female\n",
      "Sample 7: True label = Female, Predicted = Female\n",
      "Sample 8: True label = Female, Predicted = Female\n",
      "Sample 9: True label = Female, Predicted = Female\n",
      "Sample 10: True label = Female, Predicted = Female\n"
     ]
    }
   ],
   "source": [
    "for i, (true, pred) in enumerate(zip(test_labels, predictions)):\n",
    "    print(f\"Sample {i+1}: True label = {'Male' if true == 0 else 'Female'}, Predicted = {'Male' if pred == 0 else 'Female'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
