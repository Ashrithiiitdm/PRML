{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the 128- dimensional feature vectors (d=128) given in the “gender.csv” file. (2 classes, male and female)\n",
    "\n",
    "\n",
    "a) Use PCA to reduce the dimension from d to d‟. (Here d=128).\n",
    "\n",
    "\n",
    "b) Display the eigenvalue based on increasing order, select the d‟ of the corresponding eigenvector which is the appropriate dimension d‟ ( select d‟ S.T first 95% of λ values of the covariance matrix are considered).\n",
    "\n",
    "\n",
    "c) Use d‟ features to classify the test cases (use any classification algorithm taught in class like Bayes classifier, minimum distance classifier, and so on).\n",
    "\n",
    "Dataset Specifications:\n",
    "\n",
    "Total number of samples = 800\n",
    "\n",
    "Number of classes = 2 (labeled as “male” and “female”)\n",
    "\n",
    "Samples from “1 to 400” belongs to class “male”\n",
    "\n",
    "Samples from “401 to 800” belongs to class “female”\n",
    "\n",
    "Number of samples per class = 400\n",
    "\n",
    "Number of dimensions = 128\n",
    "\n",
    "Use the following information to design classifier:\n",
    "\n",
    "\n",
    "Number of test cases (first 10 in each class) = 20\n",
    "\n",
    "Number of training feature vectors ( remaining 390 in each class) = 390\n",
    "\n",
    "Number of reduced dimensions = d‟ (map 128 to d‟ features vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.read_csv('gender.csv')\n",
    "gender_df['Label'] = gender_df['Unnamed: 1']\n",
    "gender_df.drop(['Unnamed: 0', 'Unnamed: 1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.97351868e-03 -3.60642117e-04 -2.16383652e-04 ...  4.44221964e-04\n",
      "  -1.00563881e-04 -4.91091254e-05]\n",
      " [-3.60642117e-04  2.46669576e-03  5.11762350e-05 ... -3.82309128e-04\n",
      "  -1.37693470e-04 -1.87163213e-05]\n",
      " [-2.16383652e-04  5.11762350e-05  2.58212973e-03 ... -3.07653151e-04\n",
      "  -2.05282568e-04  2.86060002e-05]\n",
      " ...\n",
      " [ 4.44221964e-04 -3.82309128e-04 -3.07653151e-04 ...  2.37008172e-03\n",
      "   2.47776832e-06  1.52785404e-04]\n",
      " [-1.00563881e-04 -1.37693470e-04 -2.05282568e-04 ...  2.47776832e-06\n",
      "   2.46498262e-03  3.22312975e-05]\n",
      " [-4.91091254e-05 -1.87163213e-05  2.86060002e-05 ...  1.52785404e-04\n",
      "   3.22312975e-05  2.25878968e-03]]\n"
     ]
    }
   ],
   "source": [
    "df = gender_df.drop('Label', axis=1)\n",
    "cov_matrix = np.cov(df, rowvar = False)\n",
    "print(cov_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function for Principal Component Analysis (PCA) which takes a DataFrame as input\n",
    "def pca(X):\n",
    "    \n",
    "    # Making the data mean-centered\n",
    "    mean = np.mean(X, axis=0)\n",
    "    X = X - mean\n",
    "\n",
    "    # Calculate the covariance matrix\n",
    "    cov_matrix = np.cov(X, rowvar=False)\n",
    "\n",
    "    # Calculate the eigenvalues and eigenvectors\n",
    "    eig_values, eig_vectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "    eig_values, eig_vectors = eig_values.real, eig_vectors.real\n",
    "\n",
    "    # Sort the eigenvectors by decreasing eigenvalues\n",
    "    idx = np.argsort(eig_values)[::-1]\n",
    "\n",
    "    # Sort eigenvalues\n",
    "    eig_values = eig_values[idx]  \n",
    "\n",
    "    print(\"Eigen values after sorting\\n\", eig_values)\n",
    "\n",
    "    # Compute cumulative variance\n",
    "    variance = np.cumsum(eig_values) / np.sum(eig_values)\n",
    "\n",
    "    # Get the number of components based on the variance threshold\n",
    "    d = np.argmax(variance >= 0.95) + 1\n",
    "    print(\"New dimensions: \", d)\n",
    "\n",
    "    # Select the top d eigenvectors\n",
    "    sel_eigen_vectors = eig_vectors[:, :d]\n",
    "\n",
    "    # Project the data onto the selected eigenvectors\n",
    "    X_pca = np.dot(X, sel_eigen_vectors)\n",
    "\n",
    "    return X_pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen values after sorting\n",
      " [4.12176766e-02 2.40118775e-02 1.71111604e-02 1.45027660e-02\n",
      " 1.26813904e-02 1.18931602e-02 1.01143111e-02 9.04300685e-03\n",
      " 8.47642204e-03 7.92259881e-03 7.56723390e-03 7.13193051e-03\n",
      " 6.75919664e-03 6.47829814e-03 6.31321208e-03 5.78163452e-03\n",
      " 5.54058725e-03 5.48252160e-03 5.26469830e-03 5.03681869e-03\n",
      " 4.78933015e-03 4.52810294e-03 4.47827311e-03 4.22639684e-03\n",
      " 4.21242903e-03 3.97050356e-03 3.83249923e-03 3.66188374e-03\n",
      " 3.45420175e-03 3.36381832e-03 3.21785618e-03 3.04563338e-03\n",
      " 3.01768926e-03 2.85672221e-03 2.79537719e-03 2.70232846e-03\n",
      " 2.63687059e-03 2.55370940e-03 2.52691826e-03 2.42131249e-03\n",
      " 2.37047722e-03 2.29834291e-03 2.27518972e-03 2.14555764e-03\n",
      " 2.05654128e-03 1.99342469e-03 1.91474242e-03 1.84400602e-03\n",
      " 1.83671248e-03 1.76746631e-03 1.63982016e-03 1.59730472e-03\n",
      " 1.53753513e-03 1.47002752e-03 1.42703305e-03 1.36569109e-03\n",
      " 1.30160525e-03 1.21898058e-03 1.17783237e-03 1.16898611e-03\n",
      " 1.11811877e-03 1.05886796e-03 1.00515486e-03 9.89754891e-04\n",
      " 9.44814717e-04 9.01810969e-04 8.58160707e-04 8.41632012e-04\n",
      " 7.59863465e-04 7.24970158e-04 7.13868598e-04 6.46330547e-04\n",
      " 5.83758272e-04 5.73637420e-04 3.86753436e-04 3.46960347e-04\n",
      " 1.74796131e-04 4.59475451e-06 8.59536910e-07 3.09313739e-07\n",
      " 9.66463483e-08 9.15122989e-09 1.24960649e-09 5.47784481e-10\n",
      " 2.82872809e-10 9.55658915e-11 2.40825600e-11 9.31848435e-12\n",
      " 4.19348619e-12 2.55763700e-12 7.76062553e-13 6.85262409e-13\n",
      " 3.03254363e-13 1.60306167e-13 8.06653608e-14 5.50752502e-14\n",
      " 4.31524584e-14 3.11183761e-14 2.03140320e-14 1.15554612e-14\n",
      " 1.06712443e-14 8.09017773e-15 7.02630571e-15 6.70878613e-15\n",
      " 6.36435223e-15 5.69619733e-15 5.42280845e-15 5.11180323e-15\n",
      " 4.93303841e-15 4.62046551e-15 4.43522641e-15 4.16204671e-15\n",
      " 3.77916134e-15 3.72237319e-15 3.25257721e-15 2.96649921e-15\n",
      " 2.86261996e-15 2.70768532e-15 2.66456891e-15 2.52950602e-15\n",
      " 2.33690127e-15 2.16081630e-15 2.03681868e-15 1.92301216e-15\n",
      " 1.77470959e-15 1.59678962e-15 1.38249441e-15 1.14428205e-15]\n",
      "New dimensions:  57\n"
     ]
    }
   ],
   "source": [
    "df_reduced = pca(df)\n",
    "df_reduced = pd.DataFrame(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "      <td>8.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.776357e-17</td>\n",
       "      <td>1.498801e-17</td>\n",
       "      <td>4.996004e-18</td>\n",
       "      <td>-1.748601e-17</td>\n",
       "      <td>1.720846e-17</td>\n",
       "      <td>4.440892e-18</td>\n",
       "      <td>6.383782e-18</td>\n",
       "      <td>-8.049117e-18</td>\n",
       "      <td>7.216450e-18</td>\n",
       "      <td>-1.332268e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.049117e-18</td>\n",
       "      <td>9.645063e-18</td>\n",
       "      <td>9.436896e-18</td>\n",
       "      <td>1.942890e-18</td>\n",
       "      <td>1.967176e-17</td>\n",
       "      <td>9.436896e-18</td>\n",
       "      <td>7.736867e-18</td>\n",
       "      <td>-7.528700e-18</td>\n",
       "      <td>5.204170e-18</td>\n",
       "      <td>3.469447e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.030214e-01</td>\n",
       "      <td>1.549577e-01</td>\n",
       "      <td>1.308096e-01</td>\n",
       "      <td>1.204274e-01</td>\n",
       "      <td>1.126117e-01</td>\n",
       "      <td>1.090558e-01</td>\n",
       "      <td>1.005699e-01</td>\n",
       "      <td>9.509473e-02</td>\n",
       "      <td>9.206749e-02</td>\n",
       "      <td>8.900898e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.049469e-02</td>\n",
       "      <td>4.204125e-02</td>\n",
       "      <td>4.294189e-02</td>\n",
       "      <td>4.285688e-02</td>\n",
       "      <td>3.996629e-02</td>\n",
       "      <td>3.921142e-02</td>\n",
       "      <td>1.862687e-02</td>\n",
       "      <td>1.966605e-02</td>\n",
       "      <td>1.322105e-02</td>\n",
       "      <td>3.777609e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.546874e-01</td>\n",
       "      <td>-3.176415e-01</td>\n",
       "      <td>-3.720125e-01</td>\n",
       "      <td>-3.743110e-01</td>\n",
       "      <td>-2.812327e-01</td>\n",
       "      <td>-3.378446e-01</td>\n",
       "      <td>-2.513338e-01</td>\n",
       "      <td>-3.136177e-01</td>\n",
       "      <td>-3.233857e-01</td>\n",
       "      <td>-3.051982e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.492379e-01</td>\n",
       "      <td>-1.341538e-01</td>\n",
       "      <td>-1.152212e-01</td>\n",
       "      <td>-1.321982e-01</td>\n",
       "      <td>-1.143620e-01</td>\n",
       "      <td>-1.262619e-01</td>\n",
       "      <td>-6.095278e-02</td>\n",
       "      <td>-5.246327e-02</td>\n",
       "      <td>-3.451100e-02</td>\n",
       "      <td>-1.120404e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.050774e-01</td>\n",
       "      <td>-1.066496e-01</td>\n",
       "      <td>-8.985982e-02</td>\n",
       "      <td>-8.397985e-02</td>\n",
       "      <td>-7.359415e-02</td>\n",
       "      <td>-7.189799e-02</td>\n",
       "      <td>-7.328894e-02</td>\n",
       "      <td>-6.631901e-02</td>\n",
       "      <td>-6.393577e-02</td>\n",
       "      <td>-6.255846e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.707542e-02</td>\n",
       "      <td>-2.841119e-02</td>\n",
       "      <td>-2.901279e-02</td>\n",
       "      <td>-2.797426e-02</td>\n",
       "      <td>-2.690610e-02</td>\n",
       "      <td>-2.661118e-02</td>\n",
       "      <td>-1.171505e-02</td>\n",
       "      <td>-1.303794e-02</td>\n",
       "      <td>-8.824402e-03</td>\n",
       "      <td>-2.574077e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.959840e-02</td>\n",
       "      <td>-3.750354e-02</td>\n",
       "      <td>3.624099e-04</td>\n",
       "      <td>5.757960e-03</td>\n",
       "      <td>2.377023e-03</td>\n",
       "      <td>3.567549e-03</td>\n",
       "      <td>6.567316e-04</td>\n",
       "      <td>7.273334e-03</td>\n",
       "      <td>-1.603639e-03</td>\n",
       "      <td>-8.802275e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>2.183583e-04</td>\n",
       "      <td>-1.343643e-03</td>\n",
       "      <td>-3.714120e-04</td>\n",
       "      <td>1.625032e-03</td>\n",
       "      <td>-1.087592e-03</td>\n",
       "      <td>-8.005682e-05</td>\n",
       "      <td>7.857637e-04</td>\n",
       "      <td>-7.923597e-04</td>\n",
       "      <td>-8.755637e-04</td>\n",
       "      <td>-1.882582e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.953019e-01</td>\n",
       "      <td>7.021733e-02</td>\n",
       "      <td>9.471993e-02</td>\n",
       "      <td>8.692933e-02</td>\n",
       "      <td>7.946624e-02</td>\n",
       "      <td>7.288791e-02</td>\n",
       "      <td>6.896335e-02</td>\n",
       "      <td>6.493091e-02</td>\n",
       "      <td>6.365774e-02</td>\n",
       "      <td>6.070273e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848730e-02</td>\n",
       "      <td>2.878230e-02</td>\n",
       "      <td>2.919775e-02</td>\n",
       "      <td>2.925536e-02</td>\n",
       "      <td>2.741744e-02</td>\n",
       "      <td>2.737686e-02</td>\n",
       "      <td>1.198817e-02</td>\n",
       "      <td>1.221487e-02</td>\n",
       "      <td>8.580014e-03</td>\n",
       "      <td>2.572501e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.607476e-01</td>\n",
       "      <td>5.501217e-01</td>\n",
       "      <td>3.966303e-01</td>\n",
       "      <td>3.274456e-01</td>\n",
       "      <td>3.288025e-01</td>\n",
       "      <td>3.410586e-01</td>\n",
       "      <td>2.933661e-01</td>\n",
       "      <td>2.529252e-01</td>\n",
       "      <td>2.538657e-01</td>\n",
       "      <td>2.603154e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.219220e-01</td>\n",
       "      <td>1.279623e-01</td>\n",
       "      <td>1.645562e-01</td>\n",
       "      <td>1.125424e-01</td>\n",
       "      <td>1.552163e-01</td>\n",
       "      <td>1.288062e-01</td>\n",
       "      <td>5.586602e-02</td>\n",
       "      <td>5.768246e-02</td>\n",
       "      <td>5.419370e-02</td>\n",
       "      <td>1.257339e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  8.000000e+02  8.000000e+02  8.000000e+02  8.000000e+02  8.000000e+02   \n",
       "mean   1.776357e-17  1.498801e-17  4.996004e-18 -1.748601e-17  1.720846e-17   \n",
       "std    2.030214e-01  1.549577e-01  1.308096e-01  1.204274e-01  1.126117e-01   \n",
       "min   -3.546874e-01 -3.176415e-01 -3.720125e-01 -3.743110e-01 -2.812327e-01   \n",
       "25%   -2.050774e-01 -1.066496e-01 -8.985982e-02 -8.397985e-02 -7.359415e-02   \n",
       "50%    2.959840e-02 -3.750354e-02  3.624099e-04  5.757960e-03  2.377023e-03   \n",
       "75%    1.953019e-01  7.021733e-02  9.471993e-02  8.692933e-02  7.946624e-02   \n",
       "max    3.607476e-01  5.501217e-01  3.966303e-01  3.274456e-01  3.288025e-01   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  8.000000e+02  8.000000e+02  8.000000e+02  8.000000e+02  8.000000e+02   \n",
       "mean   4.440892e-18  6.383782e-18 -8.049117e-18  7.216450e-18 -1.332268e-17   \n",
       "std    1.090558e-01  1.005699e-01  9.509473e-02  9.206749e-02  8.900898e-02   \n",
       "min   -3.378446e-01 -2.513338e-01 -3.136177e-01 -3.233857e-01 -3.051982e-01   \n",
       "25%   -7.189799e-02 -7.328894e-02 -6.631901e-02 -6.393577e-02 -6.255846e-02   \n",
       "50%    3.567549e-03  6.567316e-04  7.273334e-03 -1.603639e-03 -8.802275e-04   \n",
       "75%    7.288791e-02  6.896335e-02  6.493091e-02  6.365774e-02  6.070273e-02   \n",
       "max    3.410586e-01  2.933661e-01  2.529252e-01  2.538657e-01  2.603154e-01   \n",
       "\n",
       "       ...            47            48            49            50  \\\n",
       "count  ...  8.000000e+02  8.000000e+02  8.000000e+02  8.000000e+02   \n",
       "mean   ... -8.049117e-18  9.645063e-18  9.436896e-18  1.942890e-18   \n",
       "std    ...  4.049469e-02  4.204125e-02  4.294189e-02  4.285688e-02   \n",
       "min    ... -1.492379e-01 -1.341538e-01 -1.152212e-01 -1.321982e-01   \n",
       "25%    ... -2.707542e-02 -2.841119e-02 -2.901279e-02 -2.797426e-02   \n",
       "50%    ...  2.183583e-04 -1.343643e-03 -3.714120e-04  1.625032e-03   \n",
       "75%    ...  2.848730e-02  2.878230e-02  2.919775e-02  2.925536e-02   \n",
       "max    ...  1.219220e-01  1.279623e-01  1.645562e-01  1.125424e-01   \n",
       "\n",
       "                 51            52            53            54            55  \\\n",
       "count  8.000000e+02  8.000000e+02  8.000000e+02  8.000000e+02  8.000000e+02   \n",
       "mean   1.967176e-17  9.436896e-18  7.736867e-18 -7.528700e-18  5.204170e-18   \n",
       "std    3.996629e-02  3.921142e-02  1.862687e-02  1.966605e-02  1.322105e-02   \n",
       "min   -1.143620e-01 -1.262619e-01 -6.095278e-02 -5.246327e-02 -3.451100e-02   \n",
       "25%   -2.690610e-02 -2.661118e-02 -1.171505e-02 -1.303794e-02 -8.824402e-03   \n",
       "50%   -1.087592e-03 -8.005682e-05  7.857637e-04 -7.923597e-04 -8.755637e-04   \n",
       "75%    2.741744e-02  2.737686e-02  1.198817e-02  1.221487e-02  8.580014e-03   \n",
       "max    1.552163e-01  1.288062e-01  5.586602e-02  5.768246e-02  5.419370e-02   \n",
       "\n",
       "                 56  \n",
       "count  8.000000e+02  \n",
       "mean   3.469447e-19  \n",
       "std    3.777609e-02  \n",
       "min   -1.120404e-01  \n",
       "25%   -2.574077e-02  \n",
       "50%   -1.882582e-04  \n",
       "75%    2.572501e-02  \n",
       "max    1.257339e-01  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reduced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I am using Baye's classifier to classify the data\n",
    "#Function to check whether the data falls under case 1\n",
    "def isCase1(mat):\n",
    "    first = mat[0][0]\n",
    "    for i in range(1, len(mat)):\n",
    "        if mat[i][i] != first:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "#If the data falls under case-1 discriminant function is computed accordingly.\n",
    "def linear_case1(w, pw, cov_mat):\n",
    "    u1 = np.mean(w, axis=0)\n",
    "    cov = cov_mat[0][0]\n",
    "    weight = u1 / cov\n",
    "    bias = np.log(pw) - 0.5 * np.dot(u1.T, u1) / (cov ** 2)\n",
    "    return weight, bias\n",
    "\n",
    "#If the data falls under case-2 discriminant function is computed accordingly.\n",
    "def linear_case2(w, pw, cov_mat):\n",
    "    u1 = np.mean(w, axis=0)\n",
    "    inv_cov = np.linalg.inv(cov_mat)\n",
    "    weight = inv_cov @ u1\n",
    "    bias = np.log(pw) - 0.5 * u1.T @ inv_cov @ u1\n",
    "    return weight, bias\n",
    "\n",
    "#If the data falls under case-3 discriminant function is computed accordingly.\n",
    "def non_linear(w, pw, cov_mat):\n",
    "    u1 = np.mean(w, axis=0)\n",
    "    inv_cov = np.linalg.inv(cov_mat)\n",
    "    weight1 = -0.5 * inv_cov\n",
    "    weight2 = inv_cov @ u1\n",
    "    bias = np.log(pw) - 0.5 * np.log(np.linalg.det(cov_mat)) - 0.5 * u1.T @ inv_cov @ u1\n",
    "    return weight1, weight2, bias\n",
    "\n",
    "\n",
    "#wieghts and biases are extracted from above functions by checking the cases for the given data.\n",
    "def bayes_classifier(w1, w2, pw1, pw2):\n",
    "    w1_cov = np.cov(w1, rowvar=False)\n",
    "    w2_cov = np.cov(w2, rowvar=False)\n",
    "    \n",
    "    if np.allclose(w1_cov, w2_cov):\n",
    "        weight1, bias1 = linear_case2(w1, pw1, w1_cov)\n",
    "        weight2, bias2 = linear_case2(w2, pw2, w2_cov)\n",
    "        return lambda x: np.dot(weight1 - weight2, x) + (bias1 - bias2)\n",
    "    elif isCase1(w1_cov) and isCase1(w2_cov):\n",
    "        weight1, bias1 = linear_case1(w1, pw1, w1_cov)\n",
    "        weight2, bias2 = linear_case1(w2, pw2, w2_cov)\n",
    "        return lambda x: np.dot(weight1 - weight2, x) + (bias1 - bias2)\n",
    "    else:\n",
    "        weight1_1, weight1_2, bias1 = non_linear(w1, pw1, w1_cov)\n",
    "        weight2_1, weight2_2, bias2 = non_linear(w2, pw2, w2_cov)\n",
    "        return lambda x: x.T @ (weight1_1 - weight2_1) @ x + np.dot(weight1_2 - weight2_2, x) + (bias1 - bias2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as first 400 are male and next 400 are female\n",
    "labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "#Test dataset first 10 in each class\n",
    "test_df = pd.concat([df_reduced[ : 10], df_reduced[400 : 410]])\n",
    "test_labels = np.array([0] * 10 + [1] * 10)\n",
    "\n",
    "#Remaining data is used for training\n",
    "train_male = df_reduced.iloc[:390]       # First 390 samples belong to \"male\"\n",
    "train_female = df_reduced.iloc[390:780]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 90.0 %\n"
     ]
    }
   ],
   "source": [
    "pw1, pw2 = 0.5, 0.5\n",
    "test_df = np.array(test_df.values)\n",
    "\n",
    "#Predictions are made using the bayes classifier\n",
    "result = bayes_classifier(train_male, train_female, pw1, pw2)\n",
    "predictions = np.array([0 if result(x) > 0 else 1 for x in test_df])\n",
    "\n",
    "#Accuracy is calculated\n",
    "accuracy = np.mean(test_labels == predictions)*100\n",
    "print(\"Accuracy of the model is\", accuracy, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: True label = Male, Predicted = Male\n",
      "Sample 2: True label = Male, Predicted = Male\n",
      "Sample 3: True label = Male, Predicted = Male\n",
      "Sample 4: True label = Male, Predicted = Male\n",
      "Sample 5: True label = Male, Predicted = Male\n",
      "Sample 6: True label = Male, Predicted = Male\n",
      "Sample 7: True label = Male, Predicted = Male\n",
      "Sample 8: True label = Male, Predicted = Female\n",
      "Sample 9: True label = Male, Predicted = Male\n",
      "Sample 10: True label = Male, Predicted = Male\n",
      "Sample 11: True label = Female, Predicted = Male\n",
      "Sample 12: True label = Female, Predicted = Female\n",
      "Sample 13: True label = Female, Predicted = Female\n",
      "Sample 14: True label = Female, Predicted = Female\n",
      "Sample 15: True label = Female, Predicted = Female\n",
      "Sample 16: True label = Female, Predicted = Female\n",
      "Sample 17: True label = Female, Predicted = Female\n",
      "Sample 18: True label = Female, Predicted = Female\n",
      "Sample 19: True label = Female, Predicted = Female\n",
      "Sample 20: True label = Female, Predicted = Female\n"
     ]
    }
   ],
   "source": [
    "for i, (true, pred) in enumerate(zip(test_labels, predictions)):\n",
    "    print(f\"Sample {i+1}: True label = {'Male' if true == 0 else 'Female'}, Predicted = {'Male' if pred == 0 else 'Female'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenfaces-Face classification using PCA (40 classes)\n",
    "\n",
    "a) Use the following “face.csv” file to classify the faces of 40 different people using PCA.\n",
    "\n",
    "b) Do not use the in-built function for implementing PCA.\n",
    "\n",
    "c) Use appropriate classifier taught in class (use any classification algorithm taught in class like Bayes classifier, minimum distance classifier, and so on)\n",
    "\n",
    "d) Refer to the following link for a description of the dataset: https://towardsdatascience.com/eigenfaces-face-classification-in-python-7b8d2af3d3ea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_df = pd.read_csv('face.csv')\n",
    "face_df.head(20)\n",
    "face_df.dropna(inplace=True)\n",
    "y = np.array(face_df['target'].values)\n",
    "face_df.drop(columns='target', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen values after sorting\n",
      " [ 1.88401756e+01  1.10717620e+01  6.30461460e+00 ... -2.62195151e-16\n",
      " -2.62195151e-16 -2.75029807e-16]\n",
      "New dimensions:  123\n"
     ]
    }
   ],
   "source": [
    "face_df_reduced = pca(face_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data set to train the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(face_df_reduced, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model using Nearest Neighbor is:  92.5 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classify the testing data using Nearest Neighbor Classifier and print the accuracy \n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of the model using Nearest Neighbor is: \", accuracy_score(y_test, pred)*100, \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
