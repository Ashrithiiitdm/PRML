{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the given data points, plot the lines of best fit for dimensionality reduction after applying LDA and PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA(X):\n",
    "\n",
    "    mean_vectors = []\n",
    "    Sw_classes = []\n",
    "    for class_label in X['Label'].unique():\n",
    "\n",
    "        #Go through each class and calculate the mean vectors\n",
    "        class_i = X[X['Label'] ==  class_label]\n",
    "        class_i = class_i.drop(columns=['Label'])\n",
    "        mean_i = np.mean(class_i, axis = 0)\n",
    "        mean_vectors.append(mean_i)\n",
    "        #print(class_i, end = '\\n')\n",
    "\n",
    "        #Calculate the within class scatter matrix\n",
    "        S_i = np.zeros((class_i.shape[1], class_i.shape[1]))\n",
    "        S_i = np.dot((class_i - mean_i).T, (class_i - mean_i))\n",
    "        Sw_classes.append(S_i)\n",
    "    \n",
    "    Sw_classes = np.array(Sw_classes)\n",
    "\n",
    "    #Add the scatter matrices of each class.\n",
    "    Sw = np.sum(Sw_classes, axis = 0)\n",
    "    print(\"The within scatter matrix for the dataset is:\\n\", Sw)\n",
    "\n",
    "    #Calculate the weights by the formula W = Sw^-1 * (mean_vector_1 - mean_vector_2)\n",
    "    weights = np.dot(np.linalg.inv(Sw), (mean_vectors[0] - mean_vectors[1]))\n",
    "    print(\"The weights for the LDA are:\\n\", weights)\n",
    "    df_reduced = np.dot(X.drop(columns=['Label']), weights)\n",
    "    df_reduced = pd.DataFrame(df_reduced)\n",
    "    return df_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    x  y  Label\n",
      "0   1  2      0\n",
      "1   3  5      0\n",
      "2   4  3      0\n",
      "3   5  6      0\n",
      "4   7  5      0\n",
      "5   6  2      1\n",
      "6   9  4      1\n",
      "7  10  1      1\n",
      "8  12  3      1\n",
      "9  13  6      1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([[1, 2, 0], [3, 5, 0], [4, 3, 0], [5, 6, 0], [7, 5, 0], [6, 2, 1], [9, 4, 1], [10, 1, 1], [12, 3, 1], [13, 6, 1]], columns = ['x', 'y', 'Label'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The within scatter matrix for the dataset is:\n",
      " [[50.  22. ]\n",
      " [22.  25.6]]\n",
      "The weights for the LDA are:\n",
      " [-0.22060302  0.22864322]\n",
      "          0  Label\n",
      "0  0.236683      0\n",
      "1  0.481407      0\n",
      "2 -0.196482      0\n",
      "3  0.268844      0\n",
      "4 -0.401005      0\n",
      "5 -0.866332      1\n",
      "6 -1.070854      1\n",
      "7 -1.977387      1\n",
      "8 -1.961307      1\n",
      "9 -1.495980      1\n"
     ]
    }
   ],
   "source": [
    "df_reduced = LDA(df)\n",
    "\n",
    "df_reduced['Label'] = df['Label']\n",
    "print(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Principal Component Analysis (PCA) which takes a DataFrame as input\n",
    "def pca(X, k):\n",
    "    \n",
    "    # Making the data mean-centered\n",
    "    mean = np.mean(X, axis=0)\n",
    "    X = X - mean\n",
    "\n",
    "    # Calculate the covariance matrix\n",
    "    cov_matrix = np.cov(X, rowvar=False)\n",
    "\n",
    "    # Calculate the eigenvalues and eigenvectors\n",
    "    eig_values, eig_vectors = np.linalg.eig(cov_matrix)\n",
    "\n",
    "    eig_values, eig_vectors = eig_values.real, eig_vectors.real\n",
    "\n",
    "    # Sort the eigenvectors by decreasing eigenvalues\n",
    "    idx = np.argsort(eig_values)[::-1]\n",
    "\n",
    "    # Sort eigenvalues\n",
    "    eig_values = eig_values[idx]  \n",
    "\n",
    "    print(\"Eigen values after sorting\\n\", eig_values)\n",
    "\n",
    "    # Select the top d eigenvectors\n",
    "    sel_eigen_vectors = eig_vectors[:, :1]\n",
    "\n",
    "    # Project the data onto the selected eigenvectors\n",
    "    X_pca = X @ sel_eigen_vectors\n",
    "\n",
    "    return X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen values after sorting\n",
      " [15.60402119  3.07375659]\n",
      "          0  Label\n",
      "0 -6.094112      0\n",
      "1 -3.911407      0\n",
      "2 -3.037727      0\n",
      "3 -1.853086      0\n",
      "4  0.080850      0\n",
      "5 -1.103791      1\n",
      "6  2.014786      1\n",
      "7  2.826273      1\n",
      "8  4.946786      1\n",
      "9  6.131427      1\n"
     ]
    }
   ],
   "source": [
    "df_pca = pca(df.drop(columns=['Label']), 1)\n",
    "df_pca = pd.DataFrame(df_pca)\n",
    "df_pca['Label'] = df['Label']\n",
    "print(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the data points after LDA\n",
    "for label in df_reduced['Label'].unique():\n",
    "    plt.scatter(df_reduced[df_reduced['Label'] == label][0], np.zeros(df_reduced[df_reduced['Label'] == label].shape[0]), label = label)\n",
    "plt.title('Data points after LDA')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting data points for PCA\n",
    "for label in df_pca['Label'].unique():\n",
    "    plt.scatter(df_pca[df_pca['Label'] == label][0], np.zeros(df_pca[df_pca['Label'] == label].shape[0]), label = label)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Data points after PCA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Consider the 128- dimensional feature vectors (d=128) given in the “gender.csv” \n",
    "\n",
    "file. (2 classes, male and female)\n",
    "\n",
    "a) Use LDA to reduce the dimension from d to d’. (Here d=128)\n",
    "\n",
    "b) Choose the direction “W‟ to reduce the dimension d’ (select appropriate d’).\n",
    "\n",
    "c) Use d’ features to classify the test cases (use any classification algorithm \n",
    "\n",
    "taught in class, Bayes classifier, minimum distance classifier, and so on).\n",
    "\n",
    "\n",
    "Dataset Specifications:\n",
    "\n",
    "Total number of samples = 800\n",
    "\n",
    "Number of classes = 2 (labeled as “male” and “female”)\n",
    "\n",
    "Samples from “1 to 400” belongs to class “male”\n",
    "\n",
    "Samples from “401 to 800” belongs to class “female”\n",
    "\n",
    "Number of samples per class = 400\n",
    "\n",
    "Number of dimensions = 128\n",
    "\n",
    "Use the following information to design classifier:\n",
    "\n",
    "Number of test cases (first 10 in each class) = 20\n",
    "\n",
    "Number of training feature vectors ( remaining 390 in each class) = 390\n",
    "\n",
    "Number of reduced dimensions = d’ (map 128 to d’ features vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.066420</td>\n",
       "      <td>0.151611</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.052771</td>\n",
       "      <td>-0.066105</td>\n",
       "      <td>-0.041232</td>\n",
       "      <td>-0.002637</td>\n",
       "      <td>-0.158467</td>\n",
       "      <td>0.130467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025989</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>0.027260</td>\n",
       "      <td>-0.046754</td>\n",
       "      <td>-0.118619</td>\n",
       "      <td>-0.163774</td>\n",
       "      <td>-0.000590</td>\n",
       "      <td>-0.076400</td>\n",
       "      <td>0.107497</td>\n",
       "      <td>0.001567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.030614</td>\n",
       "      <td>0.049667</td>\n",
       "      <td>0.008084</td>\n",
       "      <td>-0.050324</td>\n",
       "      <td>0.007649</td>\n",
       "      <td>-0.063818</td>\n",
       "      <td>-0.019530</td>\n",
       "      <td>-0.119905</td>\n",
       "      <td>0.186553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044229</td>\n",
       "      <td>-0.023900</td>\n",
       "      <td>-0.028108</td>\n",
       "      <td>0.040618</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>-0.141244</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>0.017638</td>\n",
       "      <td>0.080610</td>\n",
       "      <td>-0.015930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.096178</td>\n",
       "      <td>0.061127</td>\n",
       "      <td>0.035326</td>\n",
       "      <td>-0.035388</td>\n",
       "      <td>-0.090728</td>\n",
       "      <td>-0.018634</td>\n",
       "      <td>-0.024315</td>\n",
       "      <td>-0.139786</td>\n",
       "      <td>0.052211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111141</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>-0.029222</td>\n",
       "      <td>0.042115</td>\n",
       "      <td>-0.222173</td>\n",
       "      <td>-0.116908</td>\n",
       "      <td>0.093428</td>\n",
       "      <td>0.017391</td>\n",
       "      <td>0.057652</td>\n",
       "      <td>0.086116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.103057</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>-0.035873</td>\n",
       "      <td>-0.028163</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.007829</td>\n",
       "      <td>-0.017016</td>\n",
       "      <td>0.114907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100793</td>\n",
       "      <td>-0.002644</td>\n",
       "      <td>-0.023388</td>\n",
       "      <td>0.029497</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.119243</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>-0.015100</td>\n",
       "      <td>0.161575</td>\n",
       "      <td>0.062462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>-0.125815</td>\n",
       "      <td>0.120046</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>-0.042901</td>\n",
       "      <td>0.038215</td>\n",
       "      <td>-0.049677</td>\n",
       "      <td>-0.054258</td>\n",
       "      <td>-0.130758</td>\n",
       "      <td>0.173457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090197</td>\n",
       "      <td>0.067527</td>\n",
       "      <td>0.039926</td>\n",
       "      <td>0.047469</td>\n",
       "      <td>-0.056852</td>\n",
       "      <td>-0.076700</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.028171</td>\n",
       "      <td>0.026041</td>\n",
       "      <td>0.084135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.164731</td>\n",
       "      <td>0.064301</td>\n",
       "      <td>0.058630</td>\n",
       "      <td>-0.017420</td>\n",
       "      <td>-0.157600</td>\n",
       "      <td>-0.022536</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.072739</td>\n",
       "      <td>0.030554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095115</td>\n",
       "      <td>0.007198</td>\n",
       "      <td>-0.004655</td>\n",
       "      <td>0.023957</td>\n",
       "      <td>-0.170753</td>\n",
       "      <td>-0.136630</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.004384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.095308</td>\n",
       "      <td>0.051095</td>\n",
       "      <td>0.092913</td>\n",
       "      <td>-0.101745</td>\n",
       "      <td>-0.083153</td>\n",
       "      <td>-0.028159</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>-0.114513</td>\n",
       "      <td>0.157421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056078</td>\n",
       "      <td>0.119846</td>\n",
       "      <td>0.087470</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>-0.096594</td>\n",
       "      <td>-0.084553</td>\n",
       "      <td>0.037709</td>\n",
       "      <td>0.030732</td>\n",
       "      <td>-0.083713</td>\n",
       "      <td>0.064970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.202852</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.079731</td>\n",
       "      <td>-0.047156</td>\n",
       "      <td>-0.140062</td>\n",
       "      <td>-0.080246</td>\n",
       "      <td>0.057668</td>\n",
       "      <td>-0.122083</td>\n",
       "      <td>0.165443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066954</td>\n",
       "      <td>0.035684</td>\n",
       "      <td>-0.023112</td>\n",
       "      <td>-0.030452</td>\n",
       "      <td>-0.154243</td>\n",
       "      <td>-0.188270</td>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>-0.006257</td>\n",
       "      <td>0.039977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.088300</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.049627</td>\n",
       "      <td>-0.026011</td>\n",
       "      <td>-0.172773</td>\n",
       "      <td>0.086218</td>\n",
       "      <td>0.042710</td>\n",
       "      <td>-0.161852</td>\n",
       "      <td>0.185083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039460</td>\n",
       "      <td>0.067547</td>\n",
       "      <td>0.040426</td>\n",
       "      <td>0.028007</td>\n",
       "      <td>-0.154515</td>\n",
       "      <td>-0.127736</td>\n",
       "      <td>0.046967</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>-0.016942</td>\n",
       "      <td>0.048071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>female</td>\n",
       "      <td>-0.156201</td>\n",
       "      <td>0.055165</td>\n",
       "      <td>0.142716</td>\n",
       "      <td>-0.115393</td>\n",
       "      <td>-0.128982</td>\n",
       "      <td>-0.139830</td>\n",
       "      <td>-0.037305</td>\n",
       "      <td>-0.101402</td>\n",
       "      <td>0.048473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024955</td>\n",
       "      <td>0.066980</td>\n",
       "      <td>-0.002332</td>\n",
       "      <td>-0.045738</td>\n",
       "      <td>-0.110557</td>\n",
       "      <td>-0.014995</td>\n",
       "      <td>-0.002124</td>\n",
       "      <td>-0.010298</td>\n",
       "      <td>-0.028856</td>\n",
       "      <td>0.075323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label         0         1         2         3         4         5  \\\n",
       "0      male -0.066420  0.151611  0.027740  0.052771 -0.066105 -0.041232   \n",
       "1      male -0.030614  0.049667  0.008084 -0.050324  0.007649 -0.063818   \n",
       "2      male -0.096178  0.061127  0.035326 -0.035388 -0.090728 -0.018634   \n",
       "3      male -0.103057  0.085044  0.078333 -0.035873 -0.028163  0.004924   \n",
       "4      male -0.125815  0.120046  0.023131 -0.042901  0.038215 -0.049677   \n",
       "..      ...       ...       ...       ...       ...       ...       ...   \n",
       "795  female -0.164731  0.064301  0.058630 -0.017420 -0.157600 -0.022536   \n",
       "796  female -0.095308  0.051095  0.092913 -0.101745 -0.083153 -0.028159   \n",
       "797  female -0.202852  0.037039  0.079731 -0.047156 -0.140062 -0.080246   \n",
       "798  female -0.088300  0.063530  0.049627 -0.026011 -0.172773  0.086218   \n",
       "799  female -0.156201  0.055165  0.142716 -0.115393 -0.128982 -0.139830   \n",
       "\n",
       "            6         7         8  ...       118       119       120  \\\n",
       "0   -0.002637 -0.158467  0.130467  ...  0.025989 -0.001087  0.027260   \n",
       "1   -0.019530 -0.119905  0.186553  ...  0.044229 -0.023900 -0.028108   \n",
       "2   -0.024315 -0.139786  0.052211  ...  0.111141  0.059436 -0.029222   \n",
       "3    0.007829 -0.017016  0.114907  ...  0.100793 -0.002644 -0.023388   \n",
       "4   -0.054258 -0.130758  0.173457  ...  0.090197  0.067527  0.039926   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795  0.002864 -0.072739  0.030554  ...  0.095115  0.007198 -0.004655   \n",
       "796  0.009090 -0.114513  0.157421  ...  0.056078  0.119846  0.087470   \n",
       "797  0.057668 -0.122083  0.165443  ...  0.066954  0.035684 -0.023112   \n",
       "798  0.042710 -0.161852  0.185083  ...  0.039460  0.067547  0.040426   \n",
       "799 -0.037305 -0.101402  0.048473  ...  0.024955  0.066980 -0.002332   \n",
       "\n",
       "          121       122       123       124       125       126       127  \n",
       "0   -0.046754 -0.118619 -0.163774 -0.000590 -0.076400  0.107497  0.001567  \n",
       "1    0.040618 -0.146579 -0.141244  0.016162  0.017638  0.080610 -0.015930  \n",
       "2    0.042115 -0.222173 -0.116908  0.093428  0.017391  0.057652  0.086116  \n",
       "3    0.029497 -0.139830 -0.119243  0.005306 -0.015100  0.161575  0.062462  \n",
       "4    0.047469 -0.056852 -0.076700  0.004966  0.028171  0.026041  0.084135  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "795  0.023957 -0.170753 -0.136630  0.041614  0.031600  0.019064  0.004384  \n",
       "796  0.017481 -0.096594 -0.084553  0.037709  0.030732 -0.083713  0.064970  \n",
       "797 -0.030452 -0.154243 -0.188270  0.071086  0.037384 -0.006257  0.039977  \n",
       "798  0.028007 -0.154515 -0.127736  0.046967  0.009701 -0.016942  0.048071  \n",
       "799 -0.045738 -0.110557 -0.014995 -0.002124 -0.010298 -0.028856  0.075323  \n",
       "\n",
       "[800 rows x 129 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the dataset.\n",
    "gender_df = pd.read_csv('gender.csv')\n",
    "gender_df.rename(columns = {'Unnamed: 1': 'Label'}, inplace = True)\n",
    "gender_df.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "gender_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The within scatter matrix for the dataset is:\n",
      " [[ 2.2506239  -0.36724384  0.0211587  ...  0.32350867 -0.16354527\n",
      "  -0.10639707]\n",
      " [-0.36724384  1.92093402  0.16345657 ... -0.32531367 -0.16256513\n",
      "  -0.05737371]\n",
      " [ 0.0211587   0.16345657  1.76240414 ... -0.19711614 -0.03509416\n",
      "   0.1269321 ]\n",
      " ...\n",
      " [ 0.32350867 -0.32531367 -0.19711614 ...  1.88580894 -0.01889887\n",
      "   0.1052213 ]\n",
      " [-0.16354527 -0.16256513 -0.03509416 ... -0.01889887  1.91424641\n",
      "  -0.01886765]\n",
      " [-0.10639707 -0.05737371  0.1269321  ...  0.1052213  -0.01886765\n",
      "   1.76875313]]\n",
      "The weights for the LDA are:\n",
      " [-3443.37337923 -4595.39978993  1837.36835003  4276.18540525\n",
      " -5654.72032785  2827.1959374  -6451.4172399  -1534.62683868\n",
      "  1079.06778526  -760.88800144 -3427.73187065 -1057.44750595\n",
      " -3328.75864935 -5180.50234652  3874.99489236 -3404.98488045\n",
      " -4099.12542915  4382.52800584 -2444.31523085  4443.45418072\n",
      "   871.48599243  2174.30807209  3225.16479015 -2800.96642876\n",
      "  1473.73160839  2739.26178694   112.10899222  3320.84418297\n",
      "  3381.14555645  -102.15483475  3824.97894382   632.48713231\n",
      " -1024.70104885 -2582.60416031  1508.86942577  1902.43137407\n",
      " -3445.76680088 -4845.24410772  1402.15652448  1975.87519073\n",
      "  1399.1826067   3279.28694749   517.48495829  3176.35136747\n",
      " -3038.73129225 -3729.59921813  -289.00206947 -3316.88703918\n",
      " -1190.21678638 -4071.94612467  3945.21510983  2656.01397324\n",
      " -1947.30249786  4127.2958405   -485.49400234  2011.42624331\n",
      "  -482.79704809 -5099.6731801  -1386.08928967 -1997.60468578\n",
      " -5462.0201025  -2425.63386297 -3009.39413881  3964.40782881\n",
      "  -577.21104407  -666.84765339 -1400.68277454   747.76499271\n",
      "  6430.60954189  -918.59155178 -5504.90498352 -1551.09646678\n",
      "   699.419034   -1472.14808595  1225.37223506  2665.52979851\n",
      " -1630.45763683   738.14987946  -949.03663731 -1004.33497524\n",
      " -3606.85690629  4184.54851806  4258.34661293 -1583.01405907\n",
      "  -734.4288891    876.80614281  -362.96158838   511.88694811\n",
      "   417.49402785 -2014.23180389  1026.4585104  -2975.68068838\n",
      " -8523.13161945    26.58533359 -4451.89716578  4224.93032408\n",
      " -2284.83866841  2720.73424268 -1199.0361824   1452.65341032\n",
      "   -25.85962963  -611.89367962 -4667.67776442 -4342.95001793\n",
      " -5770.22126389 -3645.38910365  -767.30644035  5474.1093111\n",
      " -5632.12779009  6380.57118988  3327.81777811 -1291.93247628\n",
      "  1929.76655507   829.8513658  -6111.8761909  -3206.26328039\n",
      "  1729.98434353 -1481.54004383 -3466.31480551   156.31137466\n",
      "  1715.80975866  2569.57989931   219.99377012  1999.29047203\n",
      "  1933.82184923 -4864.65258694  4461.09877324 -1843.32637787]\n"
     ]
    }
   ],
   "source": [
    "gender_lda = LDA(gender_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.070974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.075027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0.024116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.011513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.021516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.014435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.013783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.070974\n",
       "1    0.075027\n",
       "2    0.067249\n",
       "3    0.068477\n",
       "4    0.069581\n",
       "..        ...\n",
       "795  0.024116\n",
       "796  0.011513\n",
       "797  0.021516\n",
       "798  0.014435\n",
       "799  0.013783\n",
       "\n",
       "[800 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as first 400 are male and next 400 are female\n",
    "labels = np.array([0] * 400 + [1] * 400)\n",
    "\n",
    "#Test dataset first 10 in each class\n",
    "test_df = pd.concat([gender_lda[ : 10], gender_lda[400 : 410]])\n",
    "test_labels = np.array([0] * 10 + [1] * 10)\n",
    "\n",
    "#Remaining data is used for training\n",
    "train_male = gender_lda.iloc[:390]       # First 390 samples belong to \"male\"\n",
    "\n",
    "#Mean for the training data\n",
    "mean_male = train_male.mean()\n",
    "\n",
    "train_female = gender_lda.iloc[390:780]\n",
    "\n",
    "#For female\n",
    "mean_female = train_female.mean()\n",
    "\n",
    "#Calculate the standard deviation for each class\n",
    "std_male = train_male.std().values[0]\n",
    "std_female = train_female.std().values[0]\n",
    "\n",
    "pw1, pw2 = 0.5, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 95.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to calculate the probability density function\n",
    "def calculate_prob(x, mean, std):\n",
    "    exponent = np.exp(-((x - mean) ** 2 / (2 * std ** 2)))\n",
    "    return (1 / (np.sqrt(2 * np.pi) * std)) * exponent\n",
    "\n",
    "# Calculate the probability of each class\n",
    "predictions = []\n",
    "for x in test_df.values:\n",
    "    prob_male = calculate_prob(x, mean_male.values[0], std_male) * pw1\n",
    "    prob_female = calculate_prob(x, mean_female.values[0], std_female) * pw2\n",
    "    predictions.append(0 if prob_male > prob_female else 1)\n",
    "\n",
    "# Convert predictions to numpy array\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(test_labels == predictions) * 100\n",
    "print(\"Accuracy of the model is\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: True label = Male, Predicted = Male\n",
      "Sample 2: True label = Male, Predicted = Male\n",
      "Sample 3: True label = Male, Predicted = Male\n",
      "Sample 4: True label = Male, Predicted = Male\n",
      "Sample 5: True label = Male, Predicted = Male\n",
      "Sample 6: True label = Male, Predicted = Male\n",
      "Sample 7: True label = Male, Predicted = Male\n",
      "Sample 8: True label = Male, Predicted = Male\n",
      "Sample 9: True label = Male, Predicted = Male\n",
      "Sample 10: True label = Male, Predicted = Male\n",
      "Sample 11: True label = Female, Predicted = Male\n",
      "Sample 12: True label = Female, Predicted = Female\n",
      "Sample 13: True label = Female, Predicted = Female\n",
      "Sample 14: True label = Female, Predicted = Female\n",
      "Sample 15: True label = Female, Predicted = Female\n",
      "Sample 16: True label = Female, Predicted = Female\n",
      "Sample 17: True label = Female, Predicted = Female\n",
      "Sample 18: True label = Female, Predicted = Female\n",
      "Sample 19: True label = Female, Predicted = Female\n",
      "Sample 20: True label = Female, Predicted = Female\n"
     ]
    }
   ],
   "source": [
    "for i, (true, pred) in enumerate(zip(test_labels, predictions)):\n",
    "    print(f\"Sample {i+1}: True label = {'Male' if true == 0 else 'Female'}, Predicted = {'Male' if pred == 0 else 'Female'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisherfaces- Face classification using LDA (40 classes)\n",
    "\n",
    "a) Use the following “face.csv” file to classify the faces of 40 different people using LDA.\n",
    "\n",
    "b) Do not use the in-built function for implementing LDA.\n",
    "\n",
    "c) Use appropriate classifier taught in class (use any classification algorithm taught in class like Bayes classifier, minimum distance classifier, and so on)\n",
    "\n",
    "d) Refer to the following link for a description of the dataset: https://towardsdatascience.com/eigenfaces-face-classification-in-python-7b8d2af3d3ea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_df = pd.read_csv('face.csv')\n",
    "face_df.rename({'target': 'Label'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights for the LDA are:\n",
      " [[ 0.02421678  0.05055599  0.01075048 ... -0.03068211  0.0097415\n",
      "  -0.03309377]\n",
      " [ 0.01327193  0.03131514  0.02697621 ... -0.01474673  0.00619009\n",
      "  -0.02558758]\n",
      " [ 0.00460519  0.00358973  0.02736976 ...  0.00010447  0.00690308\n",
      "  -0.02394577]\n",
      " ...\n",
      " [ 0.00429287  0.02459111  0.02014311 ... -0.01270796 -0.04402391\n",
      "   0.02283476]\n",
      " [-0.0026432   0.01820529 -0.05083525 ... -0.00298159 -0.03374946\n",
      "  -0.00455267]\n",
      " [-0.02447939 -0.02110352 -0.00169172 ...  0.01508498  0.00811592\n",
      "  -0.01092153]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def LDA_multiclass(X):\n",
    "\n",
    "    #Find total mean\n",
    "    total_mean = np.mean(X.drop(columns=['Label']), axis=0)\n",
    "\n",
    "    classes = X['Label'].unique()\n",
    "    Sw = np.zeros((X.shape[1] - 1, X.shape[1] - 1))  # (features, features)\n",
    "    Sb = np.zeros((X.shape[1] - 1, X.shape[1] - 1))\n",
    "\n",
    "    for class_label in classes:\n",
    "        class_i = X[X['Label'] == class_label]\n",
    "        class_i = class_i.drop(columns=['Label'])\n",
    "        mean_i = np.mean(class_i, axis=0).values\n",
    "        \n",
    "        # Within-class scatter\n",
    "        Sw_i = (class_i - mean_i).T @ (class_i - mean_i)\n",
    "        Sw += Sw_i\n",
    "\n",
    "        # Between-class scatter\n",
    "        mean_diff = (mean_i - total_mean)\n",
    "        mean_diff = np.array(mean_diff)\n",
    "        mean_diff = mean_diff.reshape(-1, 1)\n",
    "        Sb += (mean_diff @ mean_diff.T)\n",
    "\n",
    "    #Find eigen vectors and eigen values\n",
    "    eigvals, eigvecs = np.linalg.eig(np.linalg.pinv(Sw) @ Sb)\n",
    "    eigvals, eigvecs = eigvals.real, eigvecs.real\n",
    "\n",
    "\n",
    "    # Sort eigenvalues and select top n - 1 eigenvectors\n",
    "    idx = eigvals.argsort()[::-1]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    weights = eigvecs[:, :len(classes) - 1]\n",
    "    print(\"The weights for the LDA are:\\n\", weights)\n",
    "\n",
    "    # Projecting data onto new LDA space\n",
    "    df_reduced = X.drop(columns=['Label']) @ weights\n",
    "    return pd.DataFrame(df_reduced)\n",
    "\n",
    "# Example usage\n",
    "face_reduced = LDA_multiclass(face_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.213725</td>\n",
       "      <td>1.799428</td>\n",
       "      <td>-0.287967</td>\n",
       "      <td>-0.650485</td>\n",
       "      <td>-1.006593</td>\n",
       "      <td>-0.411635</td>\n",
       "      <td>-0.941690</td>\n",
       "      <td>-0.146558</td>\n",
       "      <td>-0.033369</td>\n",
       "      <td>0.051309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017480</td>\n",
       "      <td>0.114154</td>\n",
       "      <td>-0.362449</td>\n",
       "      <td>-0.091496</td>\n",
       "      <td>0.093255</td>\n",
       "      <td>0.046075</td>\n",
       "      <td>-0.238326</td>\n",
       "      <td>0.175036</td>\n",
       "      <td>-0.028399</td>\n",
       "      <td>-0.084116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.085591</td>\n",
       "      <td>1.748254</td>\n",
       "      <td>-0.303913</td>\n",
       "      <td>-0.452527</td>\n",
       "      <td>-0.944646</td>\n",
       "      <td>-0.516181</td>\n",
       "      <td>-0.929152</td>\n",
       "      <td>-0.228895</td>\n",
       "      <td>0.155577</td>\n",
       "      <td>0.210092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047369</td>\n",
       "      <td>0.100243</td>\n",
       "      <td>-0.259421</td>\n",
       "      <td>-0.209169</td>\n",
       "      <td>-0.100891</td>\n",
       "      <td>-0.022422</td>\n",
       "      <td>-0.190501</td>\n",
       "      <td>0.328642</td>\n",
       "      <td>-0.256535</td>\n",
       "      <td>-0.074705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.119848</td>\n",
       "      <td>1.806694</td>\n",
       "      <td>-0.252762</td>\n",
       "      <td>-0.572624</td>\n",
       "      <td>-1.016856</td>\n",
       "      <td>-0.449630</td>\n",
       "      <td>-0.889343</td>\n",
       "      <td>-0.027885</td>\n",
       "      <td>0.013565</td>\n",
       "      <td>0.097699</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210705</td>\n",
       "      <td>0.117787</td>\n",
       "      <td>-0.096411</td>\n",
       "      <td>-0.205707</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>-0.321190</td>\n",
       "      <td>0.408568</td>\n",
       "      <td>0.141519</td>\n",
       "      <td>-0.113635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.139900</td>\n",
       "      <td>1.710063</td>\n",
       "      <td>-0.348830</td>\n",
       "      <td>-0.235725</td>\n",
       "      <td>-0.864513</td>\n",
       "      <td>-0.474675</td>\n",
       "      <td>-0.835443</td>\n",
       "      <td>-0.215442</td>\n",
       "      <td>0.064111</td>\n",
       "      <td>0.232973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022114</td>\n",
       "      <td>-0.157923</td>\n",
       "      <td>-0.188837</td>\n",
       "      <td>-0.114539</td>\n",
       "      <td>0.242011</td>\n",
       "      <td>-0.069139</td>\n",
       "      <td>-0.119804</td>\n",
       "      <td>0.458819</td>\n",
       "      <td>0.017420</td>\n",
       "      <td>0.007335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.339819</td>\n",
       "      <td>1.664040</td>\n",
       "      <td>-0.215584</td>\n",
       "      <td>-0.382952</td>\n",
       "      <td>-0.894456</td>\n",
       "      <td>-0.452178</td>\n",
       "      <td>-1.005460</td>\n",
       "      <td>-0.020431</td>\n",
       "      <td>0.132936</td>\n",
       "      <td>0.197306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.161236</td>\n",
       "      <td>-0.131250</td>\n",
       "      <td>-0.207181</td>\n",
       "      <td>0.053298</td>\n",
       "      <td>-0.206523</td>\n",
       "      <td>-0.203810</td>\n",
       "      <td>0.074536</td>\n",
       "      <td>-0.133055</td>\n",
       "      <td>-0.144703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>4.731883</td>\n",
       "      <td>2.188341</td>\n",
       "      <td>-0.641544</td>\n",
       "      <td>-0.212540</td>\n",
       "      <td>-0.370135</td>\n",
       "      <td>-0.481774</td>\n",
       "      <td>-0.549977</td>\n",
       "      <td>-0.095101</td>\n",
       "      <td>0.164718</td>\n",
       "      <td>0.203085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203274</td>\n",
       "      <td>-0.506288</td>\n",
       "      <td>-0.282987</td>\n",
       "      <td>-0.155647</td>\n",
       "      <td>0.431231</td>\n",
       "      <td>-0.005771</td>\n",
       "      <td>-0.102093</td>\n",
       "      <td>0.422699</td>\n",
       "      <td>-0.152237</td>\n",
       "      <td>0.320699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>4.493201</td>\n",
       "      <td>2.097722</td>\n",
       "      <td>-0.703675</td>\n",
       "      <td>-0.253185</td>\n",
       "      <td>-0.279319</td>\n",
       "      <td>-0.350299</td>\n",
       "      <td>-0.766420</td>\n",
       "      <td>-0.131781</td>\n",
       "      <td>0.098811</td>\n",
       "      <td>0.369419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239451</td>\n",
       "      <td>-0.283566</td>\n",
       "      <td>-0.477303</td>\n",
       "      <td>-0.152620</td>\n",
       "      <td>0.608946</td>\n",
       "      <td>-0.065598</td>\n",
       "      <td>-0.182916</td>\n",
       "      <td>0.214692</td>\n",
       "      <td>-0.100399</td>\n",
       "      <td>0.057334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>4.467560</td>\n",
       "      <td>2.221014</td>\n",
       "      <td>-0.555761</td>\n",
       "      <td>-0.137172</td>\n",
       "      <td>-0.256853</td>\n",
       "      <td>-0.423077</td>\n",
       "      <td>-0.517627</td>\n",
       "      <td>0.018091</td>\n",
       "      <td>0.085817</td>\n",
       "      <td>0.360749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076423</td>\n",
       "      <td>-0.623910</td>\n",
       "      <td>-0.387113</td>\n",
       "      <td>-0.107602</td>\n",
       "      <td>0.451684</td>\n",
       "      <td>0.070710</td>\n",
       "      <td>-0.213446</td>\n",
       "      <td>0.292766</td>\n",
       "      <td>-0.308665</td>\n",
       "      <td>0.146419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>4.291835</td>\n",
       "      <td>2.142422</td>\n",
       "      <td>-0.510297</td>\n",
       "      <td>-0.349389</td>\n",
       "      <td>-0.401531</td>\n",
       "      <td>-0.583180</td>\n",
       "      <td>-0.555466</td>\n",
       "      <td>-0.052431</td>\n",
       "      <td>-0.069846</td>\n",
       "      <td>0.286361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137940</td>\n",
       "      <td>-0.567109</td>\n",
       "      <td>-0.342818</td>\n",
       "      <td>-0.267471</td>\n",
       "      <td>0.327643</td>\n",
       "      <td>0.210666</td>\n",
       "      <td>-0.177183</td>\n",
       "      <td>0.346824</td>\n",
       "      <td>0.059856</td>\n",
       "      <td>0.105111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>4.479165</td>\n",
       "      <td>2.242525</td>\n",
       "      <td>-0.656103</td>\n",
       "      <td>-0.028844</td>\n",
       "      <td>-0.364300</td>\n",
       "      <td>-0.648879</td>\n",
       "      <td>-0.648096</td>\n",
       "      <td>0.133264</td>\n",
       "      <td>0.067635</td>\n",
       "      <td>0.232831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085605</td>\n",
       "      <td>-0.760231</td>\n",
       "      <td>-0.298745</td>\n",
       "      <td>-0.079165</td>\n",
       "      <td>0.200867</td>\n",
       "      <td>-0.254543</td>\n",
       "      <td>-0.302204</td>\n",
       "      <td>0.457353</td>\n",
       "      <td>-0.076964</td>\n",
       "      <td>0.059278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    4.213725  1.799428 -0.287967 -0.650485 -1.006593 -0.411635 -0.941690   \n",
       "1    4.085591  1.748254 -0.303913 -0.452527 -0.944646 -0.516181 -0.929152   \n",
       "2    4.119848  1.806694 -0.252762 -0.572624 -1.016856 -0.449630 -0.889343   \n",
       "3    4.139900  1.710063 -0.348830 -0.235725 -0.864513 -0.474675 -0.835443   \n",
       "4    4.339819  1.664040 -0.215584 -0.382952 -0.894456 -0.452178 -1.005460   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "395  4.731883  2.188341 -0.641544 -0.212540 -0.370135 -0.481774 -0.549977   \n",
       "396  4.493201  2.097722 -0.703675 -0.253185 -0.279319 -0.350299 -0.766420   \n",
       "397  4.467560  2.221014 -0.555761 -0.137172 -0.256853 -0.423077 -0.517627   \n",
       "398  4.291835  2.142422 -0.510297 -0.349389 -0.401531 -0.583180 -0.555466   \n",
       "399  4.479165  2.242525 -0.656103 -0.028844 -0.364300 -0.648879 -0.648096   \n",
       "\n",
       "           7         8         9   ...        29        30        31  \\\n",
       "0   -0.146558 -0.033369  0.051309  ... -0.017480  0.114154 -0.362449   \n",
       "1   -0.228895  0.155577  0.210092  ... -0.047369  0.100243 -0.259421   \n",
       "2   -0.027885  0.013565  0.097699  ... -0.210705  0.117787 -0.096411   \n",
       "3   -0.215442  0.064111  0.232973  ... -0.022114 -0.157923 -0.188837   \n",
       "4   -0.020431  0.132936  0.197306  ...  0.002239  0.161236 -0.131250   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "395 -0.095101  0.164718  0.203085  ... -0.203274 -0.506288 -0.282987   \n",
       "396 -0.131781  0.098811  0.369419  ...  0.239451 -0.283566 -0.477303   \n",
       "397  0.018091  0.085817  0.360749  ...  0.076423 -0.623910 -0.387113   \n",
       "398 -0.052431 -0.069846  0.286361  ...  0.137940 -0.567109 -0.342818   \n",
       "399  0.133264  0.067635  0.232831  ... -0.085605 -0.760231 -0.298745   \n",
       "\n",
       "           32        33        34        35        36        37        38  \n",
       "0   -0.091496  0.093255  0.046075 -0.238326  0.175036 -0.028399 -0.084116  \n",
       "1   -0.209169 -0.100891 -0.022422 -0.190501  0.328642 -0.256535 -0.074705  \n",
       "2   -0.205707  0.002186  0.146400 -0.321190  0.408568  0.141519 -0.113635  \n",
       "3   -0.114539  0.242011 -0.069139 -0.119804  0.458819  0.017420  0.007335  \n",
       "4   -0.207181  0.053298 -0.206523 -0.203810  0.074536 -0.133055 -0.144703  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "395 -0.155647  0.431231 -0.005771 -0.102093  0.422699 -0.152237  0.320699  \n",
       "396 -0.152620  0.608946 -0.065598 -0.182916  0.214692 -0.100399  0.057334  \n",
       "397 -0.107602  0.451684  0.070710 -0.213446  0.292766 -0.308665  0.146419  \n",
       "398 -0.267471  0.327643  0.210666 -0.177183  0.346824  0.059856  0.105111  \n",
       "399 -0.079165  0.200867 -0.254543 -0.302204  0.457353 -0.076964  0.059278  \n",
       "\n",
       "[400 rows x 39 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(face_reduced, face_df['Label'], test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model using Nearest Neighbor is:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# classify the testing data using Nearest Neighbor Classifier and print the accuracy \n",
    "knn = KNeighborsClassifier(n_neighbors = 1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print(\"Accuracy of the model using Nearest Neighbor is: \", accuracy_score(y_test, pred)*100, \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
