{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this question,  you will explore the concept of Mahalanobis distance and its application to classifying samples from the Iris dataset. The Iris dataset is a commonly used dataset in machine learning and consists of three classes of iris plants: Setosa, Versicolor, and Virginica. You will compute the Mahalanobis distance for one sample from each class and classify the samples based on their Mahalanobis distance.\n",
    "Tasks:\n",
    "Load the Iris dataset (csv file present in the classroom).\n",
    "Choose one random sample from each class (Setosa, Versicolor, and Virginica) which will act as the test data.\n",
    "Compute the mean vector and covariance matrix for each class (without the sample picked in the previous part, now it will act as the test data).\n",
    "Calculate the Mahalanobis distance for each of the selected samples with each of the class using the formula:\n",
    "Mahalanobis distance = sqrt((x - μ)ᵀ * Σ⁻¹ * (x - μ))\n",
    "Where:\n",
    "x is the feature vector of the sample.\n",
    "μ is the mean vector for each class.\n",
    "Σ⁻¹ is the inverse of the covariance matrix for each class.\n",
    "\n",
    "Compare the Mahalanobis distances for the three samples and classify each sample to the class with the smallest Mahalanobis distance.\n",
    "Print the original class and the predicted class for each sample, along with their Mahalanobis distances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing dataframe:\n",
      "      sepal.length  sepal.width  petal.length  petal.width     variety\n",
      "48            5.3          3.7           1.5          0.2      Setosa\n",
      "59            5.2          2.7           3.9          1.4  Versicolor\n",
      "138           6.0          3.0           4.8          1.8   Virginica\n",
      "Training dataframe:\n",
      "      sepal.length  sepal.width  petal.length  petal.width    variety\n",
      "0             5.1          3.5           1.4          0.2     Setosa\n",
      "1             4.9          3.0           1.4          0.2     Setosa\n",
      "2             4.7          3.2           1.3          0.2     Setosa\n",
      "3             4.6          3.1           1.5          0.2     Setosa\n",
      "4             5.0          3.6           1.4          0.2     Setosa\n",
      "..            ...          ...           ...          ...        ...\n",
      "145           6.7          3.0           5.2          2.3  Virginica\n",
      "146           6.3          2.5           5.0          1.9  Virginica\n",
      "147           6.5          3.0           5.2          2.0  Virginica\n",
      "148           6.2          3.4           5.4          2.3  Virginica\n",
      "149           5.9          3.0           5.1          1.8  Virginica\n",
      "\n",
      "[147 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./iris.csv')\n",
    "test_df = []\n",
    "\n",
    "#Extract one random sample from each class\n",
    "for class_label in df['variety'].unique():\n",
    "    \n",
    "    cr = df[df['variety'] == class_label]\n",
    "    idx = random.randint(0, len(cr) - 1)\n",
    "    sample = cr.iloc[idx]\n",
    "   #print(sample)\n",
    "    test_df.append(sample)\n",
    "\n",
    "#Testing set\n",
    "test_df = pd.DataFrame(test_df)\n",
    "print(\"Testing dataframe:\\n\",test_df)\n",
    "\n",
    "#Remove testing set from the training set.\n",
    "train_df = df.drop(test_df.index)\n",
    "print(\"Training dataframe:\\n\", train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sepal.length  sepal.width  petal.length  petal.width\n",
      "variety                                                         \n",
      "Setosa             5.006        3.428         1.462        0.246\n",
      "Versicolor         5.936        2.770         4.260        1.326\n",
      "Virginica          6.588        2.974         5.552        2.026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Computing mean for each class\n",
    "mean_vector = df.groupby('variety').mean()\n",
    "print(mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for calculating the covariance between each pair of attributes in the dataset.\n",
    "#It takes two features and computes the covariance.\n",
    "\n",
    "def cov(x, y):\n",
    "\n",
    "    n = len(x)\n",
    "    \n",
    "    # Calculate means\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "    sum = 0\n",
    "    # Calculate covariance\n",
    "    for xi, yi in zip(x, y):\n",
    "        sum += (xi - mean_x) * (yi - mean_y)\n",
    "    sum /= n - 1\n",
    "    \n",
    "    return sum\n",
    "\n",
    "#Function to \n",
    "def make_matrix(df):\n",
    "    \n",
    "    #features and length of them\n",
    "    features = df.columns\n",
    "    n = len(features)\n",
    "\n",
    "    #Init a zero based matrix\n",
    "    cov_matrix = [[0] * n for _ in range(n)] \n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i <= j:\n",
    "                corr = cov(df[features[i]], df[features[j]])\n",
    "                cov_matrix[i][j] = corr\n",
    "                cov_matrix[j][i] = corr\n",
    "\n",
    "    return cov_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix for Setosa:\n",
      "[[0.12424898 0.09921633 0.0163551  0.01033061]\n",
      " [0.09921633 0.1436898  0.01169796 0.00929796]\n",
      " [0.0163551  0.01169796 0.03015918 0.00606939]\n",
      " [0.01033061 0.00929796 0.00606939 0.01110612]]\n",
      "Covariance Matrix for Versicolor:\n",
      "[[0.26643265 0.08518367 0.18289796 0.05577959]\n",
      " [0.08518367 0.09846939 0.08265306 0.04120408]\n",
      " [0.18289796 0.08265306 0.22081633 0.07310204]\n",
      " [0.05577959 0.04120408 0.07310204 0.03910612]]\n",
      "Covariance Matrix for Virginica:\n",
      "[[0.40434286 0.09376327 0.3032898  0.04909388]\n",
      " [0.09376327 0.10400408 0.07137959 0.04762857]\n",
      " [0.3032898  0.07137959 0.30458776 0.04882449]\n",
      " [0.04909388 0.04762857 0.04882449 0.07543265]]\n"
     ]
    }
   ],
   "source": [
    "final_cov = []\n",
    "\n",
    "#traversing around each class\n",
    "for class_label in df['variety'].unique():\n",
    "    cr = df[df['variety'] == class_label]\n",
    "    c_removed = cr.drop(columns = ['variety'])\n",
    "    cov_mat = make_matrix(c_removed)\n",
    "    final_cov.append(cov_mat)\n",
    "\n",
    "\n",
    "#Printing each class's covariance matrix\n",
    "for i, class_label in enumerate(df['variety'].unique()):\n",
    "    print(f\"Covariance Matrix for {class_label}:\")\n",
    "    print(np.array(final_cov[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mahalanobis distances are:\n",
      "\n",
      "[1.1454203905257336, 16.469649685600842, 21.900645321496718]\n",
      "[11.22112337557554, 2.2161285528253187, 3.001754059755531]\n",
      "[14.221055622925201, 3.6474173249202537, 1.8281873435831342]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Mahalanobis distance function\n",
    "def mahalanobis(x, mean_vector, cov_mat):\n",
    "    diff = x - mean_vector\n",
    "    cov_inv = np.linalg.inv(cov_mat)\n",
    "    dist = np.sqrt(np.dot(np.dot(diff.T, cov_inv), diff))  \n",
    "    return dist\n",
    "\n",
    "\n",
    "def distance(test_df, train_df):\n",
    "    dis = []\n",
    "    class_labels = train_df['variety'].unique()\n",
    "    for class_label in train_df['variety'].unique():\n",
    "\n",
    "        \n",
    "        cr = train_df[train_df['variety'] == class_label]\n",
    "        \n",
    "        # Drop the 'variety' column to get only feature columns\n",
    "        cf = cr.drop(columns=['variety'])\n",
    "        \n",
    "        # Calculate the mean vector and covariance matrix for the class\n",
    "        mean_vector = np.mean(cf, axis=0)\n",
    "        \n",
    "        # Transpose to get features in columns\n",
    "        cov_mat = np.cov(cf.T)  \n",
    "\n",
    "        d = []\n",
    "        for i, sample in test_df.iterrows():\n",
    "            # Convert the sample to a numpy array for calculation\n",
    "            d.append(mahalanobis(np.array(sample), mean_vector, cov_mat))\n",
    "\n",
    "        dis.append(d)  \n",
    "    \n",
    "    return dis, class_labels\n",
    "\n",
    "\n",
    "\n",
    "# Dropping the class label column from test_df (assuming it has 'variety' too)\n",
    "test_features = test_df.drop(columns=['variety'])\n",
    "\n",
    "# Call the distance function\n",
    "mahalanobis_distances, class_labels = distance(test_features, train_df)\n",
    "\n",
    "# Print the distances\n",
    "print(\"The Mahalanobis distances are:\\n\")\n",
    "for d in mahalanobis_distances:\n",
    "    print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: ['Setosa', 'Versicolor', 'Virginica']\n",
      "distances: {'Setosa': 21.900645321496718, 'Versicolor': 3.001754059755531, 'Virginica': 1.8281873435831342}\n",
      "True labels: ['Setosa', 'Versicolor', 'Virginica']\n"
     ]
    }
   ],
   "source": [
    "#Compare the Mahalanobis distances for the three samples and classify each sample to the class with the smallest Mahalanobis distance.\n",
    "def predict_assign(test_df, train_df):\n",
    "    #Get distances\n",
    "    distances, class_labels = distance(test_df, train_df)\n",
    "\n",
    "    predicted = []\n",
    "    #res = []\n",
    "\n",
    "    for i in range(len(test_df)):\n",
    "        sample_dis = []\n",
    "        for j in range(len(class_labels)):\n",
    "            sample_dis.append(distances[j][i])\n",
    "\n",
    "        min_dist = min(sample_dis)\n",
    "        predicted_class = class_labels[sample_dis.index(min_dist)]\n",
    "        predicted.append(predicted_class)\n",
    "\n",
    "    return predicted, dict(zip(class_labels, sample_dis))\n",
    "\n",
    "predicted_classes, d = predict_assign(test_features, train_df)\n",
    "print(\"Predicted classes:\", predicted_classes)\n",
    "print(\"distances:\", d)\n",
    "print(\"True labels:\", list(test_df['variety']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
